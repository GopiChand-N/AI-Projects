{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7c4c87",
   "metadata": {},
   "source": [
    "# Lesson 1: Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877df988",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file, the data/pdf file required for this lesson and the `helper` and `utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c97c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
   "metadata": {
    "height": 64,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:01.969117Z",
     "start_time": "2025-09-09T08:26:01.962907Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:02.577766Z",
     "start_time": "2025-09-09T08:26:02.570829Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "49fca250",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae2a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:05.115465Z",
     "start_time": "2025-09-09T08:26:04.565218Z"
    }
   },
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"rag.pdf\"]).load_data()\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "6b48a301",
   "metadata": {},
   "source": [
    "## Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:06.909415Z",
     "start_time": "2025-09-09T08:26:06.818552Z"
    }
   },
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
   "metadata": {
    "height": 115,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:08.349039Z",
     "start_time": "2025-09-09T08:26:08.333431Z"
    }
   },
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4.1-mini\", api_key=OPENAI_API_KEY)\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "997c7559",
   "metadata": {},
   "source": [
    "## Define Summary Index and Vector Index over the Same Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:26:13.462819Z",
     "start_time": "2025-09-09T08:26:11.863482Z"
    }
   },
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 13:56:12,866 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 401 Unauthorized\"\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAuthenticationError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[43]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mllama_index\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SummaryIndex, VectorStoreIndex\n\u001B[32m      3\u001B[39m summary_index = SummaryIndex(nodes)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m vector_index = \u001B[43mVectorStoreIndex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:75\u001B[39m, in \u001B[36mVectorStoreIndex.__init__\u001B[39m\u001B[34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;28mself\u001B[39m._embed_model = resolve_embed_model(\n\u001B[32m     71\u001B[39m     embed_model \u001B[38;5;129;01mor\u001B[39;00m Settings.embed_model, callback_manager=callback_manager\n\u001B[32m     72\u001B[39m )\n\u001B[32m     74\u001B[39m \u001B[38;5;28mself\u001B[39m._insert_batch_size = insert_batch_size\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m    \u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     81\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtransformations\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransformations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:79\u001B[39m, in \u001B[36mBaseIndex.__init__\u001B[39m\u001B[34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[39m\n\u001B[32m     77\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index_struct \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     78\u001B[39m     nodes = nodes \u001B[38;5;129;01mor\u001B[39;00m []\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     index_struct = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbuild_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[32m     81\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[32m     82\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[38;5;28mself\u001B[39m._index_struct = index_struct\n\u001B[32m     84\u001B[39m \u001B[38;5;28mself\u001B[39m._storage_context.index_store.add_index_struct(\u001B[38;5;28mself\u001B[39m._index_struct)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:309\u001B[39m, in \u001B[36mVectorStoreIndex.build_index_from_nodes\u001B[39m\u001B[34m(self, nodes, **insert_kwargs)\u001B[39m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(content_nodes) != \u001B[38;5;28mlen\u001B[39m(nodes):\n\u001B[32m    307\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mSome nodes are missing content, skipping them...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m309\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_build_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minsert_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:278\u001B[39m, in \u001B[36mVectorStoreIndex._build_index_from_nodes\u001B[39m\u001B[34m(self, nodes, **insert_kwargs)\u001B[39m\n\u001B[32m    276\u001B[39m     run_async_tasks(tasks)\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m278\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_add_nodes_to_index\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m        \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_show_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minsert_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m index_struct\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:231\u001B[39m, in \u001B[36mVectorStoreIndex._add_nodes_to_index\u001B[39m\u001B[34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001B[39m\n\u001B[32m    228\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m nodes_batch \u001B[38;5;129;01min\u001B[39;00m iter_batch(nodes, \u001B[38;5;28mself\u001B[39m._insert_batch_size):\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m     nodes_batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_node_with_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    232\u001B[39m     new_ids = \u001B[38;5;28mself\u001B[39m._vector_store.add(nodes_batch, **insert_kwargs)\n\u001B[32m    234\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._vector_store.stores_text \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._store_nodes_override:\n\u001B[32m    235\u001B[39m         \u001B[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001B[39;00m\n\u001B[32m    236\u001B[39m         \u001B[38;5;66;03m# we need to add the nodes to the index struct and document store\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:138\u001B[39m, in \u001B[36mVectorStoreIndex._get_node_with_embedding\u001B[39m\u001B[34m(self, nodes, show_progress)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_node_with_embedding\u001B[39m(\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    128\u001B[39m     nodes: Sequence[BaseNode],\n\u001B[32m    129\u001B[39m     show_progress: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    130\u001B[39m ) -> List[BaseNode]:\n\u001B[32m    131\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    132\u001B[39m \u001B[33;03m    Get tuples of id, node, and embedding.\u001B[39;00m\n\u001B[32m    133\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    136\u001B[39m \n\u001B[32m    137\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m     id_to_embed_map = \u001B[43membed_nodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    142\u001B[39m     results = []\n\u001B[32m    143\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m nodes:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\utils.py:176\u001B[39m, in \u001B[36membed_nodes\u001B[39m\u001B[34m(nodes, embed_model, show_progress)\u001B[39m\n\u001B[32m    173\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    174\u001B[39m         id_to_embed_map[node.node_id] = node.embedding\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m new_embeddings = \u001B[43membed_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_text_embedding_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtexts_to_embed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m new_id, text_embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(ids_to_embed, new_embeddings):\n\u001B[32m    181\u001B[39m     id_to_embed_map[new_id] = text_embedding\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:317\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m317\u001B[39m     result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    318\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    319\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    320\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:473\u001B[39m, in \u001B[36mBaseEmbedding.get_text_embedding_batch\u001B[39m\u001B[34m(self, texts, show_progress, **kwargs)\u001B[39m\n\u001B[32m    468\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callback_manager.event(\n\u001B[32m    469\u001B[39m     CBEventType.EMBEDDING,\n\u001B[32m    470\u001B[39m     payload={EventPayload.SERIALIZED: \u001B[38;5;28mself\u001B[39m.to_dict()},\n\u001B[32m    471\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m event:\n\u001B[32m    472\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.embeddings_cache:\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m         embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_text_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    474\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.embeddings_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    475\u001B[39m         embeddings = \u001B[38;5;28mself\u001B[39m._get_text_embeddings_cached(cur_batch)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:472\u001B[39m, in \u001B[36mOpenAIEmbedding._get_text_embeddings\u001B[39m\u001B[34m(self, texts)\u001B[39m\n\u001B[32m    463\u001B[39m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_retryable_get_embeddings\u001B[39m():\n\u001B[32m    465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m get_embeddings(\n\u001B[32m    466\u001B[39m         client,\n\u001B[32m    467\u001B[39m         texts,\n\u001B[32m    468\u001B[39m         engine=\u001B[38;5;28mself\u001B[39m._text_engine,\n\u001B[32m    469\u001B[39m         **\u001B[38;5;28mself\u001B[39m.additional_kwargs,\n\u001B[32m    470\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_retryable_get_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001B[39m, in \u001B[36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[39m\u001B[34m(*args, **kw)\u001B[39m\n\u001B[32m    336\u001B[39m copy = \u001B[38;5;28mself\u001B[39m.copy()\n\u001B[32m    337\u001B[39m wrapped_f.statistics = copy.statistics  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m338\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001B[39m, in \u001B[36mRetrying.__call__\u001B[39m\u001B[34m(self, fn, *args, **kwargs)\u001B[39m\n\u001B[32m    475\u001B[39m retry_state = RetryCallState(retry_object=\u001B[38;5;28mself\u001B[39m, fn=fn, args=args, kwargs=kwargs)\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m477\u001B[39m     do = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    478\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[32m    479\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001B[39m, in \u001B[36mBaseRetrying.iter\u001B[39m\u001B[34m(self, retry_state)\u001B[39m\n\u001B[32m    376\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.actions:\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m     result = \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:400\u001B[39m, in \u001B[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001B[39m\u001B[34m(rs)\u001B[39m\n\u001B[32m    398\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_post_retry_check_actions\u001B[39m(\u001B[38;5;28mself\u001B[39m, retry_state: \u001B[33m\"\u001B[39m\u001B[33mRetryCallState\u001B[39m\u001B[33m\"\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    399\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.iter_state.is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.retry_run_result):\n\u001B[32m--> \u001B[39m\u001B[32m400\u001B[39m         \u001B[38;5;28mself\u001B[39m._add_action_func(\u001B[38;5;28;01mlambda\u001B[39;00m rs: \u001B[43mrs\u001B[49m\u001B[43m.\u001B[49m\u001B[43moutcome\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    401\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    403\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.after \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001B[39m, in \u001B[36mRetrying.__call__\u001B[39m\u001B[34m(self, fn, *args, **kwargs)\u001B[39m\n\u001B[32m    478\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[32m    479\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m480\u001B[39m         result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    481\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[32m    482\u001B[39m         retry_state.set_exception(sys.exc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:465\u001B[39m, in \u001B[36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    463\u001B[39m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_retryable_get_embeddings\u001B[39m():\n\u001B[32m--> \u001B[39m\u001B[32m465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    466\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    467\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    468\u001B[39m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_text_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    469\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madditional_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    470\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:172\u001B[39m, in \u001B[36mget_embeddings\u001B[39m\u001B[34m(client, list_of_text, engine, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(list_of_text) <= \u001B[32m2048\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mThe batch size should not be larger than 2048.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    170\u001B[39m list_of_text = [text.replace(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m list_of_text]\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m data = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43mlist_of_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m.data\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m [d.embedding \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m data]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001B[39m, in \u001B[36mEmbeddings.create\u001B[39m\u001B[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m             embedding.embedding = np.frombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[32m    127\u001B[39m                 base64.b64decode(data), dtype=\u001B[33m\"\u001B[39m\u001B[33mfloat32\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    128\u001B[39m             ).tolist()\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[32m--> \u001B[39m\u001B[32m132\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/embeddings\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\dev\\AI-Projects\\RAG_tutorials\\agentic_rag_llama_index\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m             err.response.read()\n\u001B[32m   1046\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1047\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mAuthenticationError\u001B[39m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "f9898d3f",
   "metadata": {},
   "source": [
    "## Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "44cd7046-c714-4920-b077-b3ded917862f",
   "metadata": {
    "height": 98,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:19:51.367074Z",
     "start_time": "2025-09-09T08:19:51.315347Z"
    }
   },
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      1\u001B[39m summary_query_engine = summary_index.as_query_engine(\n\u001B[32m      2\u001B[39m     response_mode=\u001B[33m\"\u001B[39m\u001B[33mtree_summarize\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      3\u001B[39m     use_async=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      4\u001B[39m )\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m vector_query_engine = \u001B[43mvector_index\u001B[49m.as_query_engine()\n",
      "\u001B[31mNameError\u001B[39m: name 'vector_index' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
   "metadata": {
    "height": 285,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:19:42.759292Z",
     "start_time": "2025-09-09T08:19:42.706354Z"
    }
   },
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary_query_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mllama_index\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m QueryEngineTool\n\u001B[32m      4\u001B[39m summary_tool = QueryEngineTool.from_defaults(\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     query_engine=\u001B[43msummary_query_engine\u001B[49m,\n\u001B[32m      6\u001B[39m     description=(\n\u001B[32m      7\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mUseful for summarization questions related to MetaGPT\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      8\u001B[39m     ),\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m vector_tool = QueryEngineTool.from_defaults(\n\u001B[32m     12\u001B[39m     query_engine=vector_query_engine,\n\u001B[32m     13\u001B[39m     description=(\n\u001B[32m     14\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mUseful for retrieving specific context from the MetaGPT paper.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     15\u001B[39m     ),\n\u001B[32m     16\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'summary_query_engine' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "98d2c152",
   "metadata": {},
   "source": [
    "## Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
   "metadata": {
    "height": 81,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-09T08:30:24.814751Z",
     "start_time": "2025-09-09T08:30:24.769882Z"
    }
   },
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[44]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m response = \u001B[43mquery_engine\u001B[49m.query(\n\u001B[32m      2\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mHow do agents share information with other agents?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m )\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mstr\u001B[39m(response))\n",
      "\u001B[31mNameError\u001B[39m: name 'query_engine' is not defined"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "aed060ee",
   "metadata": {},
   "source": [
    "## Let's put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
